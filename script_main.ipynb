{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.special import softmax\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_MULTIPLIER_PREFIX = '0'\n",
    "DEPTH_MULTIPLIER = 25\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "#enable jupyter widgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenet_v1_'+ DEPTH_MULTIPLIER_PREFIX + str(DEPTH_MULTIPLIER)+'_'+str(IMAGE_SIZE)+'_epochs_'+str(NUM_EPOCHS)\n",
    "model_path = 'models\\\\' + model_name\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.saving.saved_model.load.KerasLayer object at 0x0000021EEF775388>\n"
     ]
    }
   ],
   "source": [
    "#init feature extractor layer\n",
    "fel = model.layers[0]\n",
    "print(fel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initialize paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\data-cifar-10\\train\n",
      "datasets\\data-cifar-10\\validation\n"
     ]
    }
   ],
   "source": [
    "#root path\n",
    "root = \"datasets\\\\data-cifar-10\"\n",
    "ROOT_TRAIN_SUBDIR = \"train\"\n",
    "ROOT_VAL_SUBDIR = \"validation\"\n",
    "root_training_set_path = os.path.join(root, ROOT_TRAIN_SUBDIR)\n",
    "root_validation_set_path = os.path.join(root, ROOT_VAL_SUBDIR)\n",
    "print(root_training_set_path)\n",
    "print(root_validation_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\svhn_test\n",
      "13068\n"
     ]
    }
   ],
   "source": [
    "# OOD data paths\n",
    "root_ood_data_path = \"datasets\\\\svhn_test\"\n",
    "print(root_ood_data_path)\n",
    "list_files = os.listdir(root_ood_data_path)\n",
    "total_ood_images = len(list_files)\n",
    "print(total_ood_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initialize folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init names\n",
    "OUTPUT_FOLDER_NAME = \"outputs\"\n",
    "DATA_NAME = \"CIFAR_10\"\n",
    "OOD_DATA_NAME = \"svhn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init features folders\n",
    "FEATURES_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"features\")\n",
    "FEATURES_DATA_FOLDER = os.path.join(FEATURES_FOLDER, DATA_NAME)\n",
    "OOD_FEATURES_DATA_FOLDER = os.path.join(FEATURES_FOLDER, OOD_DATA_NAME)\n",
    "    \n",
    "if(not os.path.exists(FEATURES_DATA_FOLDER)):\n",
    "    os.makedirs(FEATURES_DATA_FOLDER)\n",
    "\n",
    "if(not os.path.exists(OOD_FEATURES_DATA_FOLDER)):\n",
    "    os.makedirs(OOD_FEATURES_DATA_FOLDER)\n",
    "    \n",
    "#init distances folders\n",
    "DISTS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"dists\")\n",
    "DISTS_DATA_FOLDER = os.path.join(DISTS_FOLDER, DATA_NAME)\n",
    "OOD_DISTS_DATA_FOLDER = os.path.join(DISTS_FOLDER, OOD_DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(DISTS_DATA_FOLDER)):\n",
    "    os.makedirs(DISTS_DATA_FOLDER)\n",
    "\n",
    "if(not os.path.exists(OOD_DISTS_DATA_FOLDER)):\n",
    "    os.makedirs(OOD_DISTS_DATA_FOLDER)\n",
    "    \n",
    "#init closest class folders\n",
    "CLOSEST_CLASS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"closest_classes\")\n",
    "CLOSEST_CLASS_DATA_FOLDER = os.path.join(CLOSEST_CLASS_FOLDER, DATA_NAME)\n",
    "OOD_CLOSEST_CLASS_DATA_FOLDER = os.path.join(CLOSEST_CLASS_FOLDER, OOD_DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(CLOSEST_CLASS_DATA_FOLDER)):\n",
    "    os.makedirs(CLOSEST_CLASS_DATA_FOLDER)\n",
    "\n",
    "if(not os.path.exists(OOD_CLOSEST_CLASS_DATA_FOLDER)):\n",
    "    os.makedirs(OOD_CLOSEST_CLASS_DATA_FOLDER)\n",
    "    \n",
    "#init probabilities folders\n",
    "PROBABILITIES_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"probabilities\")\n",
    "PROBABILITIES_DATA_FOLDER = os.path.join(PROBABILITIES_FOLDER, DATA_NAME)\n",
    "OOD_PROBABILITIES_DATA_FOLDER = os.path.join(PROBABILITIES_FOLDER, OOD_DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(PROBABILITIES_DATA_FOLDER)):\n",
    "    os.makedirs(PROBABILITIES_DATA_FOLDER)\n",
    "    \n",
    "if(not os.path.exists(OOD_PROBABILITIES_DATA_FOLDER)):\n",
    "    os.makedirs(OOD_PROBABILITIES_DATA_FOLDER)\n",
    "\n",
    "#init labels folders\n",
    "LABELS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"labels\")\n",
    "LABELS_DATA_FOLDER = os.path.join(LABELS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(LABELS_DATA_FOLDER)):\n",
    "    os.makedirs(LABELS_DATA_FOLDER)\n",
    "    \n",
    "#init means folders\n",
    "MEANS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"means\")\n",
    "MEANS_DATA_FOLDER = os.path.join(MEANS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(MEANS_DATA_FOLDER)):\n",
    "    os.makedirs(MEANS_DATA_FOLDER)\n",
    "    \n",
    "#init radius folders\n",
    "RADIUS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"radius\")\n",
    "RADIUS_DATA_FOLDER = os.path.join(RADIUS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(RADIUS_DATA_FOLDER)):\n",
    "    os.makedirs(RADIUS_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initialize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TRAIN_DATA_COUNT = 50000\n",
    "TEMPERATURE = 100\n",
    "ALPHA = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Init generator and class names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "root_image_data_train = root_image_generator.flow_from_directory(str(root_training_set_path), target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE)\n",
    "root_image_data_validation = root_image_generator.flow_from_directory(str(root_validation_set_path), target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape:  (100, 128, 128, 3)\n",
      "Label batch shape:  (100, 10)\n"
     ]
    }
   ],
   "source": [
    "for root_image_batch, root_label_batch in root_image_data_train:\n",
    "    print(\"Image batch shape: \", root_image_batch.shape)\n",
    "    print(\"Label batch shape: \", root_label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog',\n",
       "       'Horse', 'Ship', 'Truck'], dtype='<U10')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_class_names = sorted(root_image_data_train.class_indices.items(), key=lambda pair:pair[1])\n",
    "root_class_names = np.array([key.title() for key, value in root_class_names])\n",
    "root_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of classes - 10\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = root_class_names.size\n",
    "print(\"No. of classes - \" + str(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. CIFAR 10 train features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dde3de2e724885b71f6d0553d6075f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated features for Airplane at outputs\\features\\CIFAR_10\\Airplane_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Automobile at outputs\\features\\CIFAR_10\\Automobile_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Bird at outputs\\features\\CIFAR_10\\Bird_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Cat at outputs\\features\\CIFAR_10\\Cat_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Deer at outputs\\features\\CIFAR_10\\Deer_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Dog at outputs\\features\\CIFAR_10\\Dog_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Frog at outputs\\features\\CIFAR_10\\Frog_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Horse at outputs\\features\\CIFAR_10\\Horse_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Ship at outputs\\features\\CIFAR_10\\Ship_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "Saved generated features for Truck at outputs\\features\\CIFAR_10\\Truck_train_features_with_5000_samples.npy having shape - (5000, 256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(root_class_names)\n",
    "for className in t:\n",
    "    cnt=0\n",
    "    xx=[]\n",
    "    train_set_features = np.empty((0, 256), float)\n",
    "    sub_path = os.path.join(root_training_set_path, className)\n",
    "    for filename in os.listdir(sub_path):\n",
    "        t.set_description(\"Generating features for class - \" + className)\n",
    "        cnt = cnt + 1\n",
    "        full_path = os.path.join(sub_path, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(full_path, target_size=[128, 128])\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)/255.0 #resize image\n",
    "        xx.append(x)\n",
    "        if( cnt%500 != 0):\n",
    "            continue\n",
    "            \n",
    "        #assemble features\n",
    "        xx = np.asarray(xx)\n",
    "        train_img_features = np.asarray(fel(xx))\n",
    "        train_set_features = np.vstack((train_set_features, train_img_features))\n",
    "        xx=[]\n",
    "\n",
    "    train_set_features = np.asarray(train_set_features)\n",
    "    save_name = \"{0}_train_features_with_{1}_samples.npy\".format(className, train_set_features.shape[0])\n",
    "    save_location =  os.path.join(FEATURES_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, train_set_features)\n",
    "    print(\"Saved generated features for \" + className + \" at \" + save_location + \" having shape - \" + str(train_set_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. CIFAR 10 validation features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5358edc0a1844e24a93bfc3d085045b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated features for Airplane at outputs\\features\\CIFAR_10\\Airplane_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Automobile at outputs\\features\\CIFAR_10\\Automobile_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Bird at outputs\\features\\CIFAR_10\\Bird_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Cat at outputs\\features\\CIFAR_10\\Cat_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Deer at outputs\\features\\CIFAR_10\\Deer_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Dog at outputs\\features\\CIFAR_10\\Dog_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Frog at outputs\\features\\CIFAR_10\\Frog_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Horse at outputs\\features\\CIFAR_10\\Horse_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Ship at outputs\\features\\CIFAR_10\\Ship_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "Saved generated features for Truck at outputs\\features\\CIFAR_10\\Truck_validation_features_with_1000_samples.npy having shape - (1000, 256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(root_class_names)\n",
    "for className in t:\n",
    "    cnt=0\n",
    "    xx=[]\n",
    "    validation_set_features = np.empty((0, 256), float)\n",
    "    sub_path = os.path.join(root_validation_set_path, className)\n",
    "    for filename in os.listdir(sub_path):\n",
    "        t.set_description(\"Generating features for class - \" + className)\n",
    "        cnt = cnt + 1\n",
    "        full_path = os.path.join(sub_path, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(full_path, target_size=[128, 128])\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)/255.0 #resize image\n",
    "        xx.append(x)\n",
    "        if( cnt%500 != 0):\n",
    "            continue\n",
    "            \n",
    "        #assemble features\n",
    "        xx = np.asarray(xx)\n",
    "        validation_img_features = np.asarray(fel(xx))\n",
    "        validation_set_features = np.vstack((validation_set_features, validation_img_features))\n",
    "        xx=[]\n",
    "\n",
    "    validation_set_features = np.asarray(validation_set_features)\n",
    "    save_name = \"{0}_validation_features_with_{1}_samples.npy\".format(className, validation_set_features.shape[0])\n",
    "    save_location =  os.path.join(FEATURES_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, validation_set_features)\n",
    "    print(\"Saved generated features for \" + className + \" at \" + save_location + \" having shape - \" + str(validation_set_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Svhn test features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df366abc33434c09b2d48e875828b796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating features for svhn dataset', max=13068.0, styleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved generated features for svhn at outputs\\features\\svhn\\svhn_features_with_13068_samples.npy having shape - (13068, 256)\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(list_files, desc=\"Generating features for svhn dataset\")\n",
    "cnt=0\n",
    "xx=[]\n",
    "ood_set_features = np.empty((0, 256), float)\n",
    "for filename in t:\n",
    "    cnt = cnt + 1\n",
    "    full_path = os.path.join(root_ood_data_path, filename)\n",
    "    img = tf.keras.preprocessing.image.load_img(full_path, target_size=[128, 128])\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)/255.0 #resize image\n",
    "    xx.append(x)\n",
    "    if( cnt%500 !=0 and cnt%total_ood_images!=0):\n",
    "        continue\n",
    "\n",
    "    #assemble features\n",
    "    xx = np.asarray(xx)\n",
    "    ood_img_features = np.asarray(fel(xx))\n",
    "    ood_set_features = np.vstack((ood_set_features, ood_img_features))\n",
    "    xx=[]\n",
    "\n",
    "ood_set_features = np.asarray(ood_set_features)\n",
    "save_name = \"{0}_features_with_{1}_samples.npy\".format(OOD_DATA_NAME, ood_set_features.shape[0])\n",
    "save_location =  os.path.join(OOD_FEATURES_DATA_FOLDER, save_name)\n",
    "np.save(save_location, ood_set_features)\n",
    "print(\"Saved generated features for \" + OOD_DATA_NAME + \" at \" + save_location + \" having shape - \" + str(ood_set_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating class means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15071898c80848ec91f20accf7bcd93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved generated means at outputs\\means\\CIFAR_10\\CIFAR_10_class_means.npy having shape - (10, 256)\n"
     ]
    }
   ],
   "source": [
    "class_means=[]\n",
    "t = tqdm(root_class_names)\n",
    "for className in t:\n",
    "    t.set_description(\"Calculating mean for class - \" + className)\n",
    "    save_name = \"{0}_train_features_with_{1}_samples.npy\".format(className, 5000)\n",
    "    class_features_path = os.path.join(FEATURES_DATA_FOLDER, save_name)\n",
    "    class_features = np.load(class_features_path)\n",
    "    cMean = np.mean(class_features, axis=0)\n",
    "    class_means.append(cMean)\n",
    "class_means = np.asarray(class_means)\n",
    "save_name = \"CIFAR_10_class_means.npy\"\n",
    "save_location =  os.path.join(MEANS_DATA_FOLDER, save_name)\n",
    "np.save(save_location, class_means)\n",
    "print(\"Saved generated means at \" + save_location + \" having shape - \" + str(class_means.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generating class radius**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_CLASS_SIZE = 5000\n",
    "FRACTION_TO_COVER = 0.95\n",
    "MODIFIED_PER_CLASS_SIZE = int(PER_CLASS_SIZE*FRACTION_TO_COVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load class means, if not already loaded\n",
    "save_name = \"CIFAR_10_class_means.npy\"\n",
    "save_location =  os.path.join(MEANS_DATA_FOLDER, save_name)\n",
    "class_means = np.load(save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1636914800f14aafb6f59d5ba5a13710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved generated radii at outputs\\radius\\CIFAR_10\\CIFAR_10_class_radii.npy having shape - (10,)\n"
     ]
    }
   ],
   "source": [
    "class_radii=[]\n",
    "t = tqdm(root_class_names)\n",
    "cnt = 0\n",
    "for className in t:\n",
    "    t.set_description(\"Calculating radius for class - \" + className)\n",
    "    save_name = \"{0}_train_features_with_{1}_samples.npy\".format(className, 5000)\n",
    "    save_location = os.path.join(FEATURES_DATA_FOLDER, save_name)\n",
    "    class_features = np.load(save_location)\n",
    "    radii = np.sort(np.ndarray.flatten(cdist(class_features, np.expand_dims(class_means[cnt], axis=0), metric='cosine')))\n",
    "    class_radii.append(radii[MODIFIED_PER_CLASS_SIZE])\n",
    "    cnt = cnt + 1\n",
    "class_radii = np.asarray(class_radii)\n",
    "save_name = \"CIFAR_10_class_radii.npy\"\n",
    "save_location =  os.path.join(RADIUS_DATA_FOLDER, save_name)\n",
    "np.save(save_location, class_radii)\n",
    "print(\"Saved generated radii at \" + save_location + \" having shape - \" + str(class_radii.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calculate distances & closest classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. CIFAR 10 train distances & classes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6594f204ba384787986614c354c62609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distances for Airplane at outputs\\dists\\CIFAR_10\\Airplane_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Airplane at outputs\\closest_classes\\CIFAR_10\\Airplane_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Automobile at outputs\\dists\\CIFAR_10\\Automobile_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Automobile at outputs\\closest_classes\\CIFAR_10\\Automobile_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Bird at outputs\\dists\\CIFAR_10\\Bird_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Bird at outputs\\closest_classes\\CIFAR_10\\Bird_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Cat at outputs\\dists\\CIFAR_10\\Cat_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Cat at outputs\\closest_classes\\CIFAR_10\\Cat_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Deer at outputs\\dists\\CIFAR_10\\Deer_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Deer at outputs\\closest_classes\\CIFAR_10\\Deer_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Dog at outputs\\dists\\CIFAR_10\\Dog_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Dog at outputs\\closest_classes\\CIFAR_10\\Dog_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Frog at outputs\\dists\\CIFAR_10\\Frog_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Frog at outputs\\closest_classes\\CIFAR_10\\Frog_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Horse at outputs\\dists\\CIFAR_10\\Horse_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Horse at outputs\\closest_classes\\CIFAR_10\\Horse_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Ship at outputs\\dists\\CIFAR_10\\Ship_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Ship at outputs\\closest_classes\\CIFAR_10\\Ship_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "Saved distances for Truck at outputs\\dists\\CIFAR_10\\Truck_train_distances_with_5000_samples.npy having shape - (5000,)\n",
      "Saved closest classes for Truck at outputs\\closest_classes\\CIFAR_10\\Truck_train_closest_classes_with_5000_samples.npy having shape - (5000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(root_class_names)\n",
    "for className in t:\n",
    "    train_dists = []\n",
    "    train_closest_classes = []\n",
    "    t.set_description(\"Calculating distance for class - \" + className)\n",
    "    save_name = \"{0}_train_features_with_{1}_samples.npy\".format(className, 5000)\n",
    "    save_location = os.path.join(FEATURES_DATA_FOLDER, save_name)\n",
    "    train_set_features = np.load(save_location)\n",
    "    for image_feature in train_set_features:\n",
    "        d = cdist(class_means, np.expand_dims(image_feature, axis=0), metric='cosine')\n",
    "        idx = np.argmin(d)\n",
    "        d = d[idx][0]\n",
    "        train_closest_classes.append(idx)\n",
    "        train_dists.append(d)\n",
    "        \n",
    "    train_dists = np.asarray(train_dists)\n",
    "    save_name = \"{0}_train_distances_with_{1}_samples.npy\".format(className, train_dists.shape[0])\n",
    "    save_location =  os.path.join(DISTS_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, train_dists)\n",
    "    print(\"Saved distances for \" + className + \" at \" + save_location + \" having shape - \" + str(train_dists.shape))\n",
    "    \n",
    "    train_closest_classes = np.asarray(train_closest_classes)\n",
    "    save_name = \"{0}_train_closest_classes_with_{1}_samples.npy\".format(className, train_closest_classes.shape[0])\n",
    "    save_location =  os.path.join(CLOSEST_CLASS_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, train_closest_classes)\n",
    "    print(\"Saved closest classes for \" + className + \" at \" + save_location + \" having shape - \" + str(train_closest_classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. CIFAR 10 validation distances & classes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f99cae5503483b8d21822f6e0ccd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distances for Airplane at outputs\\dists\\CIFAR_10\\Airplane_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Airplane at outputs\\closest_classes\\CIFAR_10\\Airplane_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Automobile at outputs\\dists\\CIFAR_10\\Automobile_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Automobile at outputs\\closest_classes\\CIFAR_10\\Automobile_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Bird at outputs\\dists\\CIFAR_10\\Bird_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Bird at outputs\\closest_classes\\CIFAR_10\\Bird_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Cat at outputs\\dists\\CIFAR_10\\Cat_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Cat at outputs\\closest_classes\\CIFAR_10\\Cat_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Deer at outputs\\dists\\CIFAR_10\\Deer_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Deer at outputs\\closest_classes\\CIFAR_10\\Deer_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Dog at outputs\\dists\\CIFAR_10\\Dog_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Dog at outputs\\closest_classes\\CIFAR_10\\Dog_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Frog at outputs\\dists\\CIFAR_10\\Frog_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Frog at outputs\\closest_classes\\CIFAR_10\\Frog_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Horse at outputs\\dists\\CIFAR_10\\Horse_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Horse at outputs\\closest_classes\\CIFAR_10\\Horse_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Ship at outputs\\dists\\CIFAR_10\\Ship_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Ship at outputs\\closest_classes\\CIFAR_10\\Ship_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "Saved distances for Truck at outputs\\dists\\CIFAR_10\\Truck_validation_distances_with_1000_samples.npy having shape - (1000,)\n",
      "Saved closest classes for Truck at outputs\\closest_classes\\CIFAR_10\\Truck_validation_closest_classes_with_1000_samples.npy having shape - (1000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(root_class_names)\n",
    "for className in t:\n",
    "    validation_dists = []\n",
    "    validation_closest_classes = []\n",
    "    t.set_description(\"Calculating distance for class - \" + className)\n",
    "    save_name = \"{0}_validation_features_with_{1}_samples.npy\".format(className, 1000)\n",
    "    save_location = os.path.join(FEATURES_DATA_FOLDER, save_name)\n",
    "    validation_set_features = np.load(save_location)\n",
    "    for image_feature in validation_set_features:\n",
    "        d = cdist(class_means, np.expand_dims(image_feature, axis=0), metric='cosine')\n",
    "        idx = np.argmin(d)\n",
    "        d = d[idx][0]\n",
    "        validation_closest_classes.append(idx)\n",
    "        validation_dists.append(d)\n",
    "        \n",
    "    validation_dists = np.asarray(validation_dists)\n",
    "    save_name = \"{0}_validation_distances_with_{1}_samples.npy\".format(className, validation_dists.shape[0])\n",
    "    save_location =  os.path.join(DISTS_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, validation_dists)\n",
    "    print(\"Saved distances for \" + className + \" at \" + save_location + \" having shape - \" + str(validation_dists.shape))\n",
    "    \n",
    "    validation_closest_classes = np.asarray(validation_closest_classes)\n",
    "    save_name = \"{0}_validation_closest_classes_with_{1}_samples.npy\".format(className, validation_closest_classes.shape[0])\n",
    "    save_location =  os.path.join(CLOSEST_CLASS_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, validation_closest_classes)\n",
    "    print(\"Saved closest classes for \" + className + \" at \" + save_location + \" having shape - \" + str(validation_closest_classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Svhn test distances & classes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distances for svhn at outputs\\dists\\svhn\\svhn_distances_with_13068_samples.npy having shape - (13068,)\n",
      "Saved closest classes for svhn at outputs\\closest_classes\\svhn\\svhn_closest_classes_with_13068_samples.npy having shape - (13068,)\n"
     ]
    }
   ],
   "source": [
    "ood_dists = []\n",
    "ood_closest_classes = []\n",
    "save_name = \"{0}_features_with_{1}_samples.npy\".format(OOD_DATA_NAME, 13068)\n",
    "save_location = os.path.join(OOD_FEATURES_DATA_FOLDER, save_name)\n",
    "ood_set_features = np.load(save_location)\n",
    "for image_feature in ood_set_features:\n",
    "    d = cdist(class_means, np.expand_dims(image_feature, axis=0), metric='cosine')\n",
    "    idx = np.argmin(d)\n",
    "    d = d[idx][0]\n",
    "    ood_closest_classes.append(idx)\n",
    "    ood_dists.append(d)\n",
    "\n",
    "ood_dists = np.asarray(ood_dists)\n",
    "save_name = \"{0}_distances_with_{1}_samples.npy\".format(OOD_DATA_NAME, ood_dists.shape[0])\n",
    "save_location =  os.path.join(OOD_DISTS_DATA_FOLDER, save_name)\n",
    "np.save(save_location, ood_dists)\n",
    "print(\"Saved distances for \" + OOD_DATA_NAME + \" at \" + save_location + \" having shape - \" + str(ood_dists.shape))\n",
    "\n",
    "ood_closest_classes = np.asarray(ood_closest_classes)\n",
    "save_name = \"{0}_closest_classes_with_{1}_samples.npy\".format(OOD_DATA_NAME, ood_closest_classes.shape[0])\n",
    "save_location =  os.path.join(OOD_CLOSEST_CLASS_DATA_FOLDER, save_name)\n",
    "np.save(save_location, ood_closest_classes)\n",
    "print(\"Saved closest classes for \" + OOD_DATA_NAME + \" at \" + save_location + \" having shape - \" + str(ood_closest_classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calculate probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.CIFAR 10 train probabilities__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b5658bbdb2418189bd936fc90641fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generated probabilities for Airplane at outputs\\probabilities\\CIFAR_10\\Airplane_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Airplane at outputs\\probabilities\\CIFAR_10\\Airplane_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Automobile at outputs\\probabilities\\CIFAR_10\\Automobile_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Automobile at outputs\\probabilities\\CIFAR_10\\Automobile_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Bird at outputs\\probabilities\\CIFAR_10\\Bird_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Bird at outputs\\probabilities\\CIFAR_10\\Bird_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Cat at outputs\\probabilities\\CIFAR_10\\Cat_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Cat at outputs\\probabilities\\CIFAR_10\\Cat_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Deer at outputs\\probabilities\\CIFAR_10\\Deer_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Deer at outputs\\probabilities\\CIFAR_10\\Deer_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Dog at outputs\\probabilities\\CIFAR_10\\Dog_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Dog at outputs\\probabilities\\CIFAR_10\\Dog_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Frog at outputs\\probabilities\\CIFAR_10\\Frog_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Frog at outputs\\probabilities\\CIFAR_10\\Frog_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Horse at outputs\\probabilities\\CIFAR_10\\Horse_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Horse at outputs\\probabilities\\CIFAR_10\\Horse_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Ship at outputs\\probabilities\\CIFAR_10\\Ship_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Ship at outputs\\probabilities\\CIFAR_10\\Ship_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated probabilities for Truck at outputs\\probabilities\\CIFAR_10\\Truck_train_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "Saved generated scaled probabilities for Truck at outputs\\probabilities\\CIFAR_10\\Truck_train_scaled_probabilities_with_5000_samples.npy having shape - (5000,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tqdm(root_class_names)\n",
    "for className in t:\n",
    "    cnt=0\n",
    "    xx=[]\n",
    "    train_set_probabilities = np.empty((0,), float)\n",
    "    train_set_scaled_probabilities = np.empty((0, ), float)\n",
    "    sub_path = os.path.join(root_training_set_path, className)\n",
    "    \n",
    "    #load train dists for the class\n",
    "    save_name = \"{0}_train_distances_with_{1}_samples.npy\".format(className, 5000)\n",
    "    save_location = os.path.join(DISTS_DATA_FOLDER, save_name)\n",
    "    train_dists = np.load(save_location)\n",
    "    \n",
    "    for filename in os.listdir(sub_path):\n",
    "        t.set_description(\"Generating probabilities for class - \" + className)\n",
    "        cnt = cnt + 1\n",
    "        full_path = os.path.join(sub_path, filename)\n",
    "        img = tf.keras.preprocessing.image.load_img(full_path, target_size=[128, 128])\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)/255.0 #resize image\n",
    "        xx.append(x)\n",
    "        if( cnt%500 != 0):\n",
    "            continue\n",
    "            \n",
    "            \n",
    "       #make predictions\n",
    "        xx = np.asarray(xx)\n",
    "        probabilities_batch = model.predict(xx)\n",
    "        probabilities_scaled_batch = np.empty((0,10), float)\n",
    "        for i in range(500):\n",
    "            probabilities_scaled_batch = np.vstack((probabilities_scaled_batch, softmax(probabilities_batch[i]/TEMPERATURE*train_dists[cnt-1])))\n",
    "        probabilities_batch = np.max(probabilities_batch, axis=-1)\n",
    "        probabilities_scaled_batch = np.max(probabilities_scaled_batch, axis=-1)\n",
    "        \n",
    "        train_set_probabilities = np.concatenate((train_set_probabilities, probabilities_batch))\n",
    "        train_set_scaled_probabilities = np.concatenate((train_set_scaled_probabilities, probabilities_scaled_batch))\n",
    "\n",
    "        #re-init vars\n",
    "        xx=[]\n",
    "\n",
    "    train_set_probabilities = np.asarray(train_set_probabilities)\n",
    "    save_name = \"{0}_train_probabilities_with_{1}_samples.npy\".format(className, train_set_probabilities.shape[0])\n",
    "    save_location =  os.path.join(PROBABILITIES_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, train_set_probabilities)\n",
    "    print(\"Saved generated probabilities for \" + className + \" at \" + save_location + \" having shape - \" + str(train_set_probabilities.shape))\n",
    "    \n",
    "    train_set_scaled_probabilities = np.asarray(train_set_scaled_probabilities)\n",
    "    save_name = \"{0}_train_scaled_probabilities_with_{1}_samples.npy\".format(className, train_set_scaled_probabilities.shape[0])\n",
    "    save_location =  os.path.join(PROBABILITIES_DATA_FOLDER, save_name)\n",
    "    np.save(save_location, train_set_scaled_probabilities)\n",
    "    print(\"Saved generated scaled probabilities for \" + className + \" at \" + save_location + \" having shape - \" + str(train_set_scaled_probabilities.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
