{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_MULTIPLIER_PREFIX = '0'\n",
    "DEPTH_MULTIPLIER = 25\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mobilenet_v1_'+ DEPTH_MULTIPLIER_PREFIX + str(DEPTH_MULTIPLIER)+'_'+str(IMAGE_SIZE)+'_epochs_'+str(NUM_EPOCHS)\n",
    "model_path = 'models\\\\' + model_name\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initialize paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\data-cifar-10\\train\n",
      "datasets\\data-cifar-10\\validation\n"
     ]
    }
   ],
   "source": [
    "#root path\n",
    "root = \"datasets\\\\data-cifar-10\"\n",
    "ROOT_TRAIN_SUBDIR = \"train\"\n",
    "ROOT_VAL_SUBDIR = \"validation\"\n",
    "root_training_set_path = os.path.join(root, ROOT_TRAIN_SUBDIR)\n",
    "root_validation_set_path = os.path.join(root, ROOT_VAL_SUBDIR)\n",
    "print(root_training_set_path)\n",
    "print(root_validation_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_NAME = \"outputs\"\n",
    "DATA_NAME = \"CIFAR_10\"\n",
    "\n",
    "FEATURES_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"features\")\n",
    "FEATURES_DATA_FOLDER = os.path.join(FEATURES_FOLDER, DATA_NAME)\n",
    "    \n",
    "if(not os.path.exists(FEATURES_DATA_FOLDER)):\n",
    "    os.makedirs(FEATURES_DATA_FOLDER)\n",
    "    \n",
    "MEANS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"means\")\n",
    "MEANS_DATA_FOLDER = os.path.join(MEANS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(MEANS_DATA_FOLDER)):\n",
    "    os.makedirs(MEANS_DATA_FOLDER)\n",
    "    \n",
    "DISTS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"dists\")\n",
    "DISTS_DATA_FOLDER = os.path.join(DISTS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(DISTS_DATA_FOLDER)):\n",
    "    os.makedirs(DISTS_DATA_FOLDER)\n",
    "    \n",
    "CLOSEST_CLASS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"closest_classes\")\n",
    "CLOSEST_CLASS_DATA_FOLDER = os.path.join(CLOSEST_CLASS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(CLOSEST_CLASS_DATA_FOLDER)):\n",
    "    os.makedirs(CLOSEST_CLASS_DATA_FOLDER)\n",
    "    \n",
    "LABELS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"labels\")\n",
    "LABELS_DATA_FOLDER = os.path.join(LABELS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(LABELS_DATA_FOLDER)):\n",
    "    os.makedirs(LABELS_DATA_FOLDER)\n",
    "    \n",
    "PROBABILITIES_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"probabilities\")\n",
    "PROBABILITIES_DATA_FOLDER = os.path.join(PROBABILITIES_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(PROBABILITIES_DATA_FOLDER)):\n",
    "    os.makedirs(PROBABILITIES_DATA_FOLDER)\n",
    "    \n",
    "RADIUS_FOLDER = os.path.join(OUTPUT_FOLDER_NAME, \"radius\")\n",
    "RADIUS_DATA_FOLDER = os.path.join(RADIUS_FOLDER, DATA_NAME)\n",
    "\n",
    "if(not os.path.exists(RADIUS_DATA_FOLDER)):\n",
    "    os.makedirs(RADIUS_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initialize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TRAIN_DATA_COUNT = 50000\n",
    "TEMPERATURE = 100\n",
    "ALPHA = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Init generator and class names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "root_image_data_train = root_image_generator.flow_from_directory(str(root_training_set_path), target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE)\n",
    "root_image_data_validation = root_image_generator.flow_from_directory(str(root_validation_set_path), target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape:  (100, 128, 128, 3)\n",
      "Label batch shape:  (100, 10)\n"
     ]
    }
   ],
   "source": [
    "for root_image_batch, root_label_batch in root_image_data_train:\n",
    "    print(\"Image batch shape: \", root_image_batch.shape)\n",
    "    print(\"Label batch shape: \", root_label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog',\n",
       "       'Horse', 'Ship', 'Truck'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_class_names = sorted(root_image_data_train.class_indices.items(), key=lambda pair:pair[1])\n",
    "root_class_names = np.array([key.title() for key, value in root_class_names])\n",
    "root_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of classes - 10\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = root_class_names.size\n",
    "print(\"No. of classes - \" + str(NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
